{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oE8emQONkPZ7"
      },
      "outputs": [],
      "source": [
        "#Preprocess"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OrgM-uk6kYf2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre"
      ],
      "metadata": {
        "id": "60FHdLbfkbdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import torch\n",
        "from torch.jit import script, trace\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import csv\n",
        "import random\n",
        "import re\n",
        "import os\n",
        "import unicodedata\n",
        "import codecs\n",
        "from io import open\n",
        "import itertools\n",
        "import math\n",
        "import json\n",
        "\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "corpus_name = \"cornell\"\n",
        "corpus = os.path.join(\"/content/gdrive/My Drive/data\", corpus_name)\n",
        "\n",
        "def printLines(file, n=10):\n",
        "    with open(file, 'rb') as datafile:\n",
        "        lines = datafile.readlines()\n",
        "    for line in lines[:n]:\n",
        "        print(line)\n",
        "\n",
        "printLines(os.path.join(corpus, \"utterances.jsonl\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95XcOhmpkcnX",
        "outputId": "1a65decb-41d1-4f0a-9d77-a440ef89400f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "b'{\"id\": \"L1045\", \"conversation_id\": \"L1044\", \"text\": \"They do not!\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"They\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"do\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 2, 3]}, {\"tok\": \"not\", \"tag\": \"RB\", \"dep\": \"neg\", \"up\": 1, \"dn\": []}, {\"tok\": \"!\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": \"L1044\", \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L1044\", \"conversation_id\": \"L1044\", \"text\": \"They do to!\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"They\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"do\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 2, 3]}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"dobj\", \"up\": 1, \"dn\": []}, {\"tok\": \"!\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L985\", \"conversation_id\": \"L984\", \"text\": \"I hope so.\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"I\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"hope\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 2, 3]}, {\"tok\": \"so\", \"tag\": \"RB\", \"dep\": \"advmod\", \"up\": 1, \"dn\": []}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": \"L984\", \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L984\", \"conversation_id\": \"L984\", \"text\": \"She okay?\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 1, \"toks\": [{\"tok\": \"She\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"okay\", \"tag\": \"RB\", \"dep\": \"ROOT\", \"dn\": [0, 2]}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L925\", \"conversation_id\": \"L924\", \"text\": \"Let\\'s go.\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"Let\", \"tag\": \"VB\", \"dep\": \"ROOT\", \"dn\": [2, 3]}, {\"tok\": \"\\'s\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 2, \"dn\": []}, {\"tok\": \"go\", \"tag\": \"VB\", \"dep\": \"ccomp\", \"up\": 0, \"dn\": [1]}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 0, \"dn\": []}]}]}, \"reply-to\": \"L924\", \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L924\", \"conversation_id\": \"L924\", \"text\": \"Wow\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"Wow\", \"tag\": \"UH\", \"dep\": \"ROOT\", \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L872\", \"conversation_id\": \"L870\", \"text\": \"Okay -- you\\'re gonna need to learn how to lie.\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 4, \"toks\": [{\"tok\": \"Okay\", \"tag\": \"UH\", \"dep\": \"intj\", \"up\": 4, \"dn\": []}, {\"tok\": \"--\", \"tag\": \":\", \"dep\": \"punct\", \"up\": 4, \"dn\": []}, {\"tok\": \"you\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 4, \"dn\": []}, {\"tok\": \"\\'re\", \"tag\": \"VBP\", \"dep\": \"aux\", \"up\": 4, \"dn\": []}, {\"tok\": \"gon\", \"tag\": \"VBG\", \"dep\": \"ROOT\", \"dn\": [0, 1, 2, 3, 6, 12]}, {\"tok\": \"na\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 6, \"dn\": []}, {\"tok\": \"need\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 4, \"dn\": [5, 8]}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 8, \"dn\": []}, {\"tok\": \"learn\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 6, \"dn\": [7, 11]}, {\"tok\": \"how\", \"tag\": \"WRB\", \"dep\": \"advmod\", \"up\": 11, \"dn\": []}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 11, \"dn\": []}, {\"tok\": \"lie\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 8, \"dn\": [9, 10]}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 4, \"dn\": []}]}]}, \"reply-to\": \"L871\", \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L871\", \"conversation_id\": \"L870\", \"text\": \"No\", \"speaker\": \"u2\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"No\", \"tag\": \"UH\", \"dep\": \"ROOT\", \"dn\": []}]}]}, \"reply-to\": \"L870\", \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L870\", \"conversation_id\": \"L870\", \"text\": \"I\\'m kidding.  You know how sometimes you just become this \\\\\"persona\\\\\"?  And you don\\'t know how to quit?\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 2, \"toks\": [{\"tok\": \"I\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 2, \"dn\": []}, {\"tok\": \"\\'m\", \"tag\": \"VBP\", \"dep\": \"aux\", \"up\": 2, \"dn\": []}, {\"tok\": \"kidding\", \"tag\": \"VBG\", \"dep\": \"ROOT\", \"dn\": [0, 1, 3]}, {\"tok\": \".\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 2, \"dn\": [4]}, {\"tok\": \" \", \"tag\": \"_SP\", \"dep\": \"\", \"up\": 3, \"dn\": []}]}, {\"rt\": 1, \"toks\": [{\"tok\": \"You\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 1, \"dn\": []}, {\"tok\": \"know\", \"tag\": \"VBP\", \"dep\": \"ROOT\", \"dn\": [0, 6, 11]}, {\"tok\": \"how\", \"tag\": \"WRB\", \"dep\": \"advmod\", \"up\": 3, \"dn\": []}, {\"tok\": \"sometimes\", \"tag\": \"RB\", \"dep\": \"advmod\", \"up\": 6, \"dn\": [2]}, {\"tok\": \"you\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 6, \"dn\": []}, {\"tok\": \"just\", \"tag\": \"RB\", \"dep\": \"advmod\", \"up\": 6, \"dn\": []}, {\"tok\": \"become\", \"tag\": \"VBP\", \"dep\": \"ccomp\", \"up\": 1, \"dn\": [3, 4, 5, 9]}, {\"tok\": \"this\", \"tag\": \"DT\", \"dep\": \"det\", \"up\": 9, \"dn\": []}, {\"tok\": \"\\\\\"\", \"tag\": \"``\", \"dep\": \"punct\", \"up\": 9, \"dn\": []}, {\"tok\": \"persona\", \"tag\": \"NN\", \"dep\": \"attr\", \"up\": 6, \"dn\": [7, 8, 10]}, {\"tok\": \"\\\\\"\", \"tag\": \"\\'\\'\", \"dep\": \"punct\", \"up\": 9, \"dn\": []}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 1, \"dn\": [12]}, {\"tok\": \" \", \"tag\": \"_SP\", \"dep\": \"\", \"up\": 11, \"dn\": []}]}, {\"rt\": 4, \"toks\": [{\"tok\": \"And\", \"tag\": \"CC\", \"dep\": \"cc\", \"up\": 4, \"dn\": []}, {\"tok\": \"you\", \"tag\": \"PRP\", \"dep\": \"nsubj\", \"up\": 4, \"dn\": []}, {\"tok\": \"do\", \"tag\": \"VBP\", \"dep\": \"aux\", \"up\": 4, \"dn\": []}, {\"tok\": \"n\\'t\", \"tag\": \"RB\", \"dep\": \"neg\", \"up\": 4, \"dn\": []}, {\"tok\": \"know\", \"tag\": \"VB\", \"dep\": \"ROOT\", \"dn\": [0, 1, 2, 3, 7, 8]}, {\"tok\": \"how\", \"tag\": \"WRB\", \"dep\": \"advmod\", \"up\": 7, \"dn\": []}, {\"tok\": \"to\", \"tag\": \"TO\", \"dep\": \"aux\", \"up\": 7, \"dn\": []}, {\"tok\": \"quit\", \"tag\": \"VB\", \"dep\": \"xcomp\", \"up\": 4, \"dn\": [5, 6]}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 4, \"dn\": []}]}]}, \"reply-to\": null, \"timestamp\": null, \"vectors\": []}\\n'\n",
            "b'{\"id\": \"L869\", \"conversation_id\": \"L866\", \"text\": \"Like my fear of wearing pastels?\", \"speaker\": \"u0\", \"meta\": {\"movie_id\": \"m0\", \"parsed\": [{\"rt\": 0, \"toks\": [{\"tok\": \"Like\", \"tag\": \"IN\", \"dep\": \"ROOT\", \"dn\": [2, 6]}, {\"tok\": \"my\", \"tag\": \"PRP$\", \"dep\": \"poss\", \"up\": 2, \"dn\": []}, {\"tok\": \"fear\", \"tag\": \"NN\", \"dep\": \"pobj\", \"up\": 0, \"dn\": [1, 3]}, {\"tok\": \"of\", \"tag\": \"IN\", \"dep\": \"prep\", \"up\": 2, \"dn\": [4]}, {\"tok\": \"wearing\", \"tag\": \"VBG\", \"dep\": \"pcomp\", \"up\": 3, \"dn\": [5]}, {\"tok\": \"pastels\", \"tag\": \"NNS\", \"dep\": \"dobj\", \"up\": 4, \"dn\": []}, {\"tok\": \"?\", \"tag\": \".\", \"dep\": \"punct\", \"up\": 0, \"dn\": []}]}]}, \"reply-to\": \"L868\", \"timestamp\": null, \"vectors\": []}\\n'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#setup the data, load dataset from the utterances.jsonl and create a python data, \n",
        "# pytorch vocabulary setup courtesy Pytorch\n",
        "def loadlines(fileName):\n",
        "    lines = {}\n",
        "    conversations = {}\n",
        "    with open(fileName, 'r', encoding='iso-8859-1') as f:\n",
        "        for line in f:\n",
        "            lineJson = json.loads(line)\n",
        "            #get the field object for line\n",
        "            lineObj = {}\n",
        "            lineObj[\"lineID\"] = lineJson[\"id\"]\n",
        "            lineObj[\"characterID\"] = lineJson[\"speaker\"]\n",
        "            lineObj[\"text\"] = lineJson[\"text\"]\n",
        "            lines[lineObj['lineID']] = lineObj\n",
        "\n",
        "             #get the field object for convos\n",
        "            if lineJson[\"conversation_id\"] not in conversations:\n",
        "                convObj = {}\n",
        "                convObj[\"conversationID\"] = lineJson[\"conversation_id\"]\n",
        "                convObj[\"movieID\"] = lineJson[\"meta\"][\"movie_id\"]\n",
        "                convObj[\"lines\"] = [lineObj]\n",
        "            else:\n",
        "                convObj = conversations[lineJson[\"conversation_id\"]]\n",
        "                convObj[\"lines\"].insert(0, lineObj)\n",
        "            conversations[convObj[\"conversationID\"]] = convObj\n",
        "\n",
        "    return lines, conversations\n",
        "\n",
        "\n",
        "# Extracts pairs of sentences from conversations\n",
        "def extractSentencePairs(conversations):\n",
        "    qa_pairs = []\n",
        "    for conversation in conversations.values():\n",
        "        # Iterate over all the lines of the conversation\n",
        "        for i in range(len(conversation[\"lines\"]) - 1): \n",
        "            inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
        "            targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
        "            # only select lines if both input and output present\n",
        "            if inputLine and targetLine:\n",
        "                qa_pairs.append([inputLine, targetLine])\n",
        "    return qa_pairs\n",
        "  \n",
        "# Setup FilePath\n",
        "# Upload the file in data/cornell/ in gooogle drive\n",
        "datafile = os.path.join(corpus, \"formatted_movie_lines.txt\")\n",
        "delimiter = '\\t'\n",
        "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
        "\n",
        "# Initialize lines dict and conversations dict\n",
        "lines = {}\n",
        "conversations = {}\n",
        "# Load lines and conversations\n",
        "print(\"Loading Lines and Conversations from Datatset, saving them locally\")\n",
        "lines, conversations =loadlines(os.path.join(corpus, \"utterances.jsonl\"))\n",
        "# Write new csv file\n",
        "print(\"\\nWriting newly formatted file...\")\n",
        "with open(datafile, 'w', encoding='utf-8') as outputfile:\n",
        "    writer = csv.writer(outputfile, delimiter=delimiter, lineterminator='\\n')\n",
        "    for pair in extractSentencePairs(conversations):\n",
        "        writer.writerow(pair)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHjNEQ1dkkSC",
        "outputId": "ff210777-efca-4388-c791-92a3e59fcc05"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Lines and Conversations from Datatset, saving them locally\n",
            "\n",
            "Writing newly formatted file...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Helper Function class \n",
        "  #We will set the length of sentence that we will consider\n",
        "MAX_LENGTH = 10  # Maximum sentence length to consider\n",
        "class SetVocab:\n",
        "  def __init__(self,vocab,corpus, corpus_name, datafile):\n",
        "    self.vocab = vocab\n",
        "    self.corpus = corpus\n",
        "    self.datafile = datafile\n",
        "    self.corpus_name = corpus_name\n",
        "\n",
        "  def unicodeToAscii(self,s):\n",
        "      return ''.join(\n",
        "          c for c in unicodedata.normalize('NFD', s)\n",
        "          if unicodedata.category(c) != 'Mn'\n",
        "      )\n",
        "\n",
        "  # Lowercase, trim, and remove non-letter characters\n",
        "  def normalizeString(self,s):\n",
        "      s = self.unicodeToAscii(s.lower().strip())\n",
        "      s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "      s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "      s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
        "      return s\n",
        "\n",
        "  # Read query/response pairs and return a voc object\n",
        "  def readVocs(self):\n",
        "      print(\"Reading lines...\")\n",
        "      # Read the file and split into lines\n",
        "      lines = open(self.datafile, encoding='utf-8').\\\n",
        "          read().strip().split('\\n')\n",
        "      # Split every line into pairs and normalize\n",
        "      pairs = [[self.normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "      voc = self.vocab(self.corpus_name)\n",
        "      return voc, pairs\n",
        "\n",
        "  # Returns True iff both sentences in a pair 'p' are under the MAX_LENGTH threshold\n",
        "  def filterPair(self,p):\n",
        "      # Input sequences need to preserve the last word for EOS token\n",
        "      return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "  # Filter pairs using filterPair condition\n",
        "  def filterPairs(self,pairs):\n",
        "      return [pair for pair in pairs if self.filterPair(pair)]\n",
        "\n"
      ],
      "metadata": {
        "id": "3tcerCwPDBak"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create default tokens, these will be used to pad or signal\n",
        "#sentence functionalities to the encoder\n",
        "PAD_token = 0  # Used for padding short sentences\n",
        "SOS_token = 1  # Start-of-sentence token\n",
        "EOS_token = 2  # End-of-sentence token\n",
        "\n",
        "#Build a chatbot vocabulary based on the word corpus that we have \n",
        "class ChatbotVocab:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        # we will define later\n",
        "        self.trimmed = False\n",
        "        #create dictionaries to store the index and the count for each word in the corpus\n",
        "        self.maptoindex = {}\n",
        "        self.maptocount = {}\n",
        "        #map index to word for faster retrieval\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3  # Count SOS, EOS, PAD, consider unique only\n",
        "        self.trimmed = False\n",
        "\n",
        "    #any time we pass a sentence to the vocah\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    #called by the sentence for each word it hass\n",
        "    def addWord(self, word):\n",
        "      \"\"\"\n",
        "      Check if the word is in the corpus\n",
        "      If not create new identity for it\n",
        "      create an index for it, set count\n",
        "      Increment the number of words in vocab\n",
        "      \"\"\"\n",
        "      if word not in self.maptoindex:\n",
        "\n",
        "          self.maptoindex[word] = self.num_words\n",
        "          self.maptocount[word] = 1\n",
        "          self.index2word[self.num_words] = word\n",
        "          self.num_words += 1\n",
        "      else:\n",
        "          self.maptocount[word] += 1\n",
        "\n",
        "    # Avoid noise by trimming certain words that are rare\n",
        "    def trim(self, min_count=3):\n",
        "        if self.trimmed:\n",
        "            return\n",
        "        self.trimmed = True\n",
        "\n",
        "        keep_words = []\n",
        "\n",
        "        for k, v in self.maptocount.items():\n",
        "            if v >= min_count:\n",
        "                keep_words.append(k)\n",
        "\n",
        "        print('Keeping only these many words {} / {} = {:.4f}'.format(\n",
        "            len(keep_words), len(self.maptoindex), len(keep_words) / len(self.maptoindex)\n",
        "        ))\n",
        "\n",
        "        # Reset and add all non trimmed words again dictionaries\n",
        "        self.maptoindex = {}\n",
        "        self.maptocount = {}\n",
        "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.num_words = 3 # Count default tokens\n",
        "\n",
        "        for word in keep_words:\n",
        "            self.addWord(word)\n",
        "\n",
        "\n",
        "def trimRareWords(voc, pairs, MIN_COUNT):\n",
        "    # Trim words used under the MIN_COUNT from the voc\n",
        "    \n",
        "    voc.trim(MIN_COUNT)\n",
        "    # Filter out pairs with trimmed words\n",
        "    keep_pairs = []\n",
        "    for pair in pairs:\n",
        "        input_sentence = pair[0]\n",
        "        output_sentence = pair[1]\n",
        "        keep_input = True\n",
        "        keep_output = True\n",
        "        # Check input sentence\n",
        "        for word in input_sentence.split(' '):\n",
        "            if word not in voc.maptoindex:\n",
        "                keep_input = False\n",
        "                break\n",
        "        # Check output sentence\n",
        "        for word in output_sentence.split(' '):\n",
        "            if word not in voc.maptoindex:\n",
        "                keep_output = False\n",
        "                break\n",
        "\n",
        "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
        "        if keep_input and keep_output:\n",
        "            keep_pairs.append(pair)\n",
        "\n",
        "    print(\"Trimmed to {} pairs\".format(len(keep_pairs)))\n",
        "    return keep_pairs\n",
        "\n",
        "# Using the functions defined above, return a populated voc object and pairs list\n",
        "def loadPrepareData(corpus, corpus_name, datafile, save_dir):\n",
        "    print(\"Start preparing training data ...\")\n",
        "    #Create the Vocab Helper Class by \n",
        "    setup_voc = SetVocab(ChatbotVocab,corpus, corpus_name,datafile)\n",
        "    voc, pairs = setup_voc.readVocs()\n",
        "    pairs = setup_voc.filterPairs(pairs)\n",
        "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        voc.addSentence(pair[0])\n",
        "        voc.addSentence(pair[1])\n",
        "    MIN_COUNT = 3    # Minimum word count threshold for trimming\n",
        "    #trim the pairs\n",
        "    pairs = trimRareWords(voc, pairs,MIN_COUNT)\n",
        "    return voc, pairs\n",
        "\n",
        "\n",
        "# Load/Assemble voc and pairs\n",
        "save_dir = os.path.join(\"data\", \"save\")\n",
        "voc, pairs = loadPrepareData(corpus, corpus_name, datafile, save_dir)\n",
        "print(f'Words in our courpus {voc.num_words}')\n",
        "print(f'Number of pairs {len(pairs)}')\n",
        "# Print some pairs to validate\n",
        "print(\"\\npairs:\")\n",
        "for pair in pairs[:5]:\n",
        "    print(pair)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpSW4OTaksvD",
        "outputId": "34700509-3e90-4a79-f42b-3f0dcafc9054"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start preparing training data ...\n",
            "Reading lines...\n",
            "Trimmed to 64313 sentence pairs\n",
            "Counting words...\n",
            "Keeping only these many words 7833 / 18079 = 0.4333\n",
            "Trimmed to 53131 pairs\n",
            "Words in our courpus 7836\n",
            "Number of pairs 53131\n",
            "\n",
            "pairs:\n",
            "['they do to !', 'they do not !']\n",
            "['she okay ?', 'i hope so .']\n",
            "['wow', 'let s go .']\n",
            "['what good stuff ?', 'the real you .']\n",
            "['do you listen to this crap ?', 'what crap ?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a batch from the sequences\n",
        "def sent2index(voc, sentence):\n",
        "    #return the index of each word in the corpus\n",
        "    return [voc.maptoindex[word] for word in sentence.split(' ')] + [EOS_token]\n",
        "\n",
        "\n",
        "def Padding(l, fillvalue=PAD_token):\n",
        "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
        "\n",
        "def binaryMask(l, value=PAD_token):\n",
        "    m = []\n",
        "    for i, seq in enumerate(l):\n",
        "        m.append([])\n",
        "        for token in seq:\n",
        "            if token == PAD_token:\n",
        "                m[i].append(0)\n",
        "            else:\n",
        "                m[i].append(1)\n",
        "    return m\n",
        "\n",
        "# Returns padded input sequence tensor and lengths\n",
        "def inputBatch(l, voc):\n",
        "    indexes_batch = [sent2index(voc, sentence) for sentence in l]\n",
        "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
        "    padList = Padding(indexes_batch)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, lengths\n",
        "\n",
        "# Returns padded target sequence tensor, padding mask, and max target length\n",
        "def outputBathc(l, voc):\n",
        "    indexes_batch = [sent2index(voc, sentence) for sentence in l]\n",
        "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
        "    padList = Padding(indexes_batch)\n",
        "    mask = binaryMask(padList)\n",
        "    mask = torch.BoolTensor(mask)\n",
        "    padVar = torch.LongTensor(padList)\n",
        "    return padVar, mask, max_target_len\n",
        "\n",
        "# Returns all items for a given batch of pairs\n",
        "# Returns all items for a given batch of pairs\n",
        "def batch2TrainData(voc, pair_batch):\n",
        "    input_batch, output_batch = [], []\n",
        "    for pair in pair_batch:\n",
        "        input_batch.append(pair[0])\n",
        "        output_batch.append(pair[1])\n",
        "    inp, lengths = inputBatch(input_batch, voc)\n",
        "    output, mask, max_target_len = outputBathc(output_batch, voc)\n",
        "    return inp, lengths, output, mask, max_target_len\n",
        "\n"
      ],
      "metadata": {
        "id": "4A71HZ0Wmx4e"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Transformer"
      ],
      "metadata": {
        "id": "b-MkA3WLn0Qr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Custom Dataset and Dataloader"
      ],
      "metadata": {
        "id": "BIVf46E2Ng-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into trian and validate\n",
        "validation_set_size = 0.2 \n",
        "dataset_size = len(pairs)\n",
        "validation_size = int(validation_set_size * dataset_size)\n",
        "train_size = dataset_size - validation_size"
      ],
      "metadata": {
        "id": "8gTiXN3nPjsc"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NXIo5tq8arM3"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "\n",
        "import torch\n",
        "#Create a Dataloader\n",
        "class Dataset_pairs(torch.utils.data.Dataset):\n",
        "  'Make a dataset from the already existing pairs'\n",
        "  def __init__(self, pairs):\n",
        "        'Initialization'\n",
        "        self.pairs = pairs\n",
        "\n",
        "  def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.pairs)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "\n",
        "        pair = self.pairs[index]\n",
        "        # Load data and get label\n",
        "        \n",
        "\n",
        "        return pair \n",
        "\n",
        "CustomData = Dataset_pairs(pairs)\n",
        "\n",
        "#The pairs from dataloader will be sent to the collate function, we will \n",
        "#get the desired output from here\n",
        "def collate_fn(batch):\n",
        "    op = batch2TrainData(voc,batch)\n",
        "    return op\n",
        "\n",
        "# Split the dataset into training and validation subsets\n",
        "train_dataset, val_dataset = random_split(CustomData, [train_size, validation_size])\n",
        "\n",
        "# Define batch sizes for training and validation\n",
        "batch_size = 64\n",
        "# Create data loaders for training and validation\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True,collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "qAcAl0Q0Ncfo"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
        "#                   ]\n",
        "# print('tr')\n",
        "# print(training_batches)\n",
        "# print('tn')\n",
        "# b = [random.choice(pairs) for _ in range(5)]\n",
        "# print(b)\n",
        "# i = 0\n",
        "# for batch in train_loader:\n",
        "#   print(batch)\n",
        "#   if(i==0):\n",
        "#     break\n",
        "    "
      ],
      "metadata": {
        "id": "ZPqSGuST47pL"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Luong Attention, GRU gates Encoder Decoder"
      ],
      "metadata": {
        "id": "Bx9tF00En5vp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MpQ_dIV6pZNH"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "import math\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class GRUencoder(nn.Module):\n",
        "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
        "        super(GRUencoder, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = embedding\n",
        "\n",
        "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
        "        #   because our input size is a word embedding with number of features == hidden_size\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
        "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
        "\n",
        "    def forward(self, input_seq, input_lengths, hidden=None):\n",
        "        # Convert word indexes to embeddings\n",
        "        embedded = self.embedding(input_seq)\n",
        "        # Pack padded batch of sequences for RNN module\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths,enforce_sorted=False)\n",
        "        # Forward pass through GRU\n",
        "        outputs, hidden = self.gru(packed, hidden)\n",
        "        # Unpack padding\n",
        "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
        "        # Sum bidirectional GRU outputs\n",
        "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
        "        # Return output and final hidden state\n",
        "        return outputs, hidden\n",
        "\n",
        "\n",
        "\n",
        "# Luong attention layer\n",
        "class Attn(nn.Module):\n",
        "    def __init__(self, method, hidden_size):\n",
        "        super(Attn, self).__init__()\n",
        "        self.hidden_size = hidden_size     \n",
        "        self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
        "\n",
        "    def general_score(self, hidden, encoder_output):\n",
        "        energy = self.attn(encoder_output)\n",
        "        return torch.sum(hidden * energy, dim=2)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        attn_energies = self.general_score(hidden, encoder_outputs)\n",
        "        attn_weights = attn_energies.t()\n",
        "\n",
        "        # Return the softmax normalized probability scores (with added dimension)\n",
        "        return F.softmax(attn_weights, dim=1).unsqueeze(1)\n",
        "\n",
        "\n",
        "\n",
        "class LuongAttnDecoderGRU(nn.Module):\n",
        "    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
        "        super(LuongAttnDecoderGRU, self).__init__()\n",
        "\n",
        "        # Keep for reference\n",
        "        self.attn_model = attn_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Define layers\n",
        "        self.embedding = embedding\n",
        "        self.embedding_dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n",
        "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        self.attn = Attn(attn_model, hidden_size)\n",
        "\n",
        "    def forward(self, input_step, last_hidden, encoder_outputs):\n",
        "        # Get embedding of current input word\n",
        "        embedded = self.embedding(input_step)\n",
        "        embedded = self.embedding_dropout(embedded)\n",
        "        # Forward through unidirectional GRU\n",
        "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
        "        # Calculate attention weights from the current GRU output\n",
        "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
        "        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n",
        "        rnn_output = rnn_output.squeeze(0)\n",
        "        context = context.squeeze(1)\n",
        "        concat_input = torch.cat((rnn_output, context), 1)\n",
        "        concat_output = torch.tanh(self.concat(concat_input))\n",
        "        # Predict next word using Luong eq. 6\n",
        "        output = self.out(concat_output)\n",
        "        output = F.softmax(output, dim=1)\n",
        "        # Return output and final hidden state for next work\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "s7PBgqD1n_u4"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Custom Dataset and Dataloader\n",
        "pairs[1][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_2m2sVn6pbCl",
        "outputId": "25c55000-3731-4e0c-bb0f-8469bc782b00"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i hope so .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Pipeline"
      ],
      "metadata": {
        "id": "YBGFE4b1wrLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def maskNLLLoss(inp, target, mask):\n",
        "    nTotal = mask.sum()\n",
        "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
        "    loss = crossEntropy.masked_select(mask).mean()\n",
        "    loss = loss.to(device)\n",
        "    return loss, nTotal.item()\n",
        "\n",
        "\n",
        "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,encoder_optimizer, decoder_optimizer, batch_size, clip,teacher_forcing_ratio, max_length=MAX_LENGTH):\n",
        "    encoder.train()\n",
        "    decoder.train()   #model will train \n",
        "    # Zero gradients\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    # Set device options\n",
        "    input_variable = input_variable.to(device)\n",
        "    target_variable = target_variable.to(device)\n",
        "    mask = mask.to(device)\n",
        "    # Lengths for inputs\n",
        "    lengths = lengths.to(\"cpu\")\n",
        "\n",
        "    # Initialize variables\n",
        "    loss = 0\n",
        "    batch_loss = []\n",
        "    n_totals = 0\n",
        "\n",
        "    # Forward pass through encoder\n",
        "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
        "\n",
        "    # give ititlal SOS input to the decoder\n",
        "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
        "    decoder_input = decoder_input.to(device)\n",
        "\n",
        "    # set decoer states\n",
        "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "\n",
        "    # Setup Teacher Forcing Ratio\n",
        "    TF_flag = True if random.random() < teacher_forcing_ratio else False\n",
        "    if TF_flag:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            # Teacher forcing: next input is current target\n",
        "            decoder_input = target_variable[t].view(1, -1)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            batch_loss.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "    else:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            # No teacher forcing: next input is decoder's own current output\n",
        "            #decide the top softmax output\n",
        "            _, topval = decoder_output.topk(1)\n",
        "            decoder_input = torch.LongTensor([[topval[i][0] for i in range(batch_size)]])\n",
        "            decoder_input = decoder_input.to(device)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            batch_loss.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "\n",
        "    # Perform backpropatation\n",
        "    loss.backward()\n",
        "\n",
        "    # Clip gradients\n",
        "    _ = nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
        "    _ = nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
        "\n",
        "    # Adjust model weights\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return sum(batch_loss) / n_totals\n",
        "\n",
        "\n",
        "def validate(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,encoder_optimizer, decoder_optimizer, batch_size, clip,teacher_forcing_ratio, max_length=MAX_LENGTH):\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    # Zero gradients\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    # Set device options\n",
        "    input_variable = input_variable.to(device)\n",
        "    target_variable = target_variable.to(device)\n",
        "    mask = mask.to(device)\n",
        "    # Lengths for rnn packing should always be on the cpu\n",
        "    lengths = lengths.to(\"cpu\")\n",
        "\n",
        "    # Initialize variables\n",
        "    loss = 0\n",
        "    print_losses = []\n",
        "    n_totals = 0\n",
        "\n",
        "    # Forward pass through encoder\n",
        "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
        "\n",
        "    # Create initial decoder input (start with SOS tokens for each sentence)\n",
        "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
        "    decoder_input = decoder_input.to(device)\n",
        "\n",
        "    # Set initial decoder hidden state to the encoder's final hidden state\n",
        "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
        "\n",
        "    # Determine if we are using teacher forcing this iteration\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    # Forward batch of sequences through decoder one time step at a time\n",
        "    if use_teacher_forcing:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            # Teacher forcing: next input is current target\n",
        "            decoder_input = target_variable[t].view(1, -1)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "    else:\n",
        "        for t in range(max_target_len):\n",
        "            decoder_output, decoder_hidden = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            #decide the top softmax output\n",
        "            _, topval = decoder_output.topk(1)\n",
        "            decoder_input = torch.LongTensor([[topval[i][0] for i in range(batch_size)]])\n",
        "            decoder_input = decoder_input.to(device)\n",
        "            # Calculate and accumulate loss\n",
        "            mask_loss, nTotal = maskNLLLoss(decoder_output, target_variable[t], mask[t])\n",
        "            loss += mask_loss\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "\n",
        "          ##No backprop here \n",
        "\n",
        "    return sum(print_losses) / n_totals\n"
      ],
      "metadata": {
        "id": "vu7D3iVAwuTs"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Training"
      ],
      "metadata": {
        "id": "iqlzuDHjpfVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Parameters\n",
        "# Configure training/optimization\n",
        "\n",
        "#Setup Parameter Based on Best Result Observed in WandB\n",
        "clip = 25.0\n",
        "teacher_forcing_ratio = 1.0\n",
        "learning_rate = 0.00025\n",
        "decoder_learning_ratio = 3.0\n",
        "n_iteration = 4000\n",
        "print_every = 1\n",
        "save_every = 100\n",
        "MAX_LENGTH = 10\n",
        "\n",
        "attn_model = 'general'\n",
        "hidden_size = 500\n",
        "encoder_n_layers = 2\n",
        "decoder_n_layers = 2\n",
        "dropout = 0.1\n",
        "batch_size = 64\n",
        "\n",
        "# build models\n",
        "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
        "encoder = GRUencoder(hidden_size, embedding, encoder_n_layers, dropout)\n",
        "decoder = LuongAttnDecoderGRU(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
        "# Use appropriate device\n",
        "encoder = encoder.to(device)\n",
        "decoder = decoder.to(device)\n",
        "print('models created')\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_token)\n",
        "\n",
        "# Initialize optimizers\n",
        "print('Change optimizers here')\n",
        "encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
        "\n",
        "# Ensure dropout layers are in train mode\n",
        "encoder.train()\n",
        "decoder.train()\n",
        "\n"
      ],
      "metadata": {
        "id": "EYO_n_g7phM7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09bb0ba0-4bf6-4b05-8288-4a0e678f7862"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models created\n",
            "Change optimizers here\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LuongAttnDecoderGRU(\n",
              "  (embedding): Embedding(7836, 500)\n",
              "  (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
              "  (gru): GRU(500, 500, num_layers=2, dropout=0.1)\n",
              "  (concat): Linear(in_features=1000, out_features=500, bias=True)\n",
              "  (out): Linear(in_features=500, out_features=7836, bias=True)\n",
              "  (attn): Attn(\n",
              "    (attn): Linear(in_features=500, out_features=500, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
        "#                   ]\n",
        "# print('tr')\n",
        "# print(training_batches)\n",
        "# print('tn')\n",
        "# b = [random.choice(pairs) for _ in range(5)]\n",
        "# print(b)\n",
        "# i = 0\n",
        "# for batch in train_loader:\n",
        "#   print(batch)\n",
        "#   if(i==0):\n",
        "#     break"
      ],
      "metadata": {
        "id": "4T_tmg34QkcJ"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Epochs/\n",
        "total_epochs = 1\n",
        "batch_size = 64\n",
        "for epoch in range(1,total_epochs+1):\n",
        "  # training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
        "  #                   for _ in range(n_iteration)]\n",
        "  \n",
        "  #train\n",
        "  print_mul = 1\n",
        "  print_counter = 0\n",
        "  for i,batch_pair in enumerate(train_loader):    \n",
        "    input_variable, lengths, target_variable, mask, max_target_len = batch_pair\n",
        "    # Run a training iteration with batch\n",
        "    loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
        "    \n",
        "                  decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip,teacher_forcing_ratio)\n",
        "    print_counter+=1\n",
        "    print_mul+=1\n",
        "    if(print_counter == 5):\n",
        "      print(\"Epoch: {}| iterations complete: {} | loss at this iteration {}\".format(epoch, print_mul*print_counter,loss))\n",
        "      print_counter = 0\n",
        "  print('Epoch Training done, Now validating')\n",
        "  #validate\n",
        "  for batch_pair in val_loader:\n",
        "    \n",
        "    val_loss = 0\n",
        "    #keep input_variable and variable lenght\n",
        "    # train_batch = training_batches[iter-1\n",
        "    tot_loss = 0\n",
        "    \n",
        "    #keep input_variable and variable lenght\n",
        "    # train_batch = training_batches[iter-1\n",
        "\n",
        "    input_variable, lengths, target_variable, mask, max_target_len = batch_pair\n",
        "    # Run a training iteration with batch\n",
        "    loss = validate(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
        "                  decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip,teacher_forcing_ratio)\n",
        "    val_loss += loss\n",
        "    \n",
        "  print(\"Epoch: {}| Percent complete: {:.1f}%| Average loss: {:.4f}| Val loss: {:.4f}\".format(epoch, epoch / total_epochs * 100,tot_loss,val_loss))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pUOMz5NMq0BJ",
        "outputId": "a76d7be6-04d2-4cf9-a0ab-2314c766e3f2"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1| iterations complete: 30 | loss at this iteration 4.4050077812984965\n",
            "Epoch: 1| iterations complete: 55 | loss at this iteration 4.368306592970111\n",
            "Epoch: 1| iterations complete: 80 | loss at this iteration 4.1428665204581865\n",
            "Epoch: 1| iterations complete: 105 | loss at this iteration 4.070235240951325\n",
            "Epoch: 1| iterations complete: 130 | loss at this iteration 4.194320168243206\n",
            "Epoch: 1| iterations complete: 155 | loss at this iteration 4.0713642584136025\n",
            "Epoch: 1| iterations complete: 180 | loss at this iteration 4.214334791670193\n",
            "Epoch: 1| iterations complete: 205 | loss at this iteration 3.9103517552847586\n",
            "Epoch: 1| iterations complete: 230 | loss at this iteration 4.207560038185233\n",
            "Epoch: 1| iterations complete: 255 | loss at this iteration 3.890459941358375\n",
            "Epoch: 1| iterations complete: 280 | loss at this iteration 4.03373944519823\n",
            "Epoch: 1| iterations complete: 305 | loss at this iteration 4.363158554621721\n",
            "Epoch: 1| iterations complete: 330 | loss at this iteration 4.149680220692379\n",
            "Epoch: 1| iterations complete: 355 | loss at this iteration 3.655466678717564\n",
            "Epoch: 1| iterations complete: 380 | loss at this iteration 4.120143934133818\n",
            "Epoch: 1| iterations complete: 405 | loss at this iteration 3.998829677547376\n",
            "Epoch: 1| iterations complete: 430 | loss at this iteration 4.104361768644898\n",
            "Epoch: 1| iterations complete: 455 | loss at this iteration 3.7970777190871217\n",
            "Epoch: 1| iterations complete: 480 | loss at this iteration 3.9371733450196422\n",
            "Epoch: 1| iterations complete: 505 | loss at this iteration 4.122717783528956\n",
            "Epoch: 1| iterations complete: 530 | loss at this iteration 3.8242444014293433\n",
            "Epoch: 1| iterations complete: 555 | loss at this iteration 4.026808964951077\n",
            "Epoch: 1| iterations complete: 580 | loss at this iteration 4.0584776600598556\n",
            "Epoch: 1| iterations complete: 605 | loss at this iteration 4.131217860577457\n",
            "Epoch: 1| iterations complete: 630 | loss at this iteration 4.497099032075129\n",
            "Epoch: 1| iterations complete: 655 | loss at this iteration 3.823876113862526\n",
            "Epoch: 1| iterations complete: 680 | loss at this iteration 3.9959960133980608\n",
            "Epoch: 1| iterations complete: 705 | loss at this iteration 4.04242171753259\n",
            "Epoch: 1| iterations complete: 730 | loss at this iteration 3.755182163779987\n",
            "Epoch: 1| iterations complete: 755 | loss at this iteration 3.75966291418776\n",
            "Epoch: 1| iterations complete: 780 | loss at this iteration 3.841609960080194\n",
            "Epoch: 1| iterations complete: 805 | loss at this iteration 3.797179816401723\n",
            "Epoch: 1| iterations complete: 830 | loss at this iteration 3.810751922066147\n",
            "Epoch: 1| iterations complete: 855 | loss at this iteration 3.986916588523339\n",
            "Epoch: 1| iterations complete: 880 | loss at this iteration 3.929932337032432\n",
            "Epoch: 1| iterations complete: 905 | loss at this iteration 3.6905869234381172\n",
            "Epoch: 1| iterations complete: 930 | loss at this iteration 4.088985944596621\n",
            "Epoch: 1| iterations complete: 955 | loss at this iteration 3.760705900192261\n",
            "Epoch: 1| iterations complete: 980 | loss at this iteration 3.75374411968868\n",
            "Epoch: 1| iterations complete: 1005 | loss at this iteration 4.107513907895639\n",
            "Epoch: 1| iterations complete: 1030 | loss at this iteration 4.019876719820194\n",
            "Epoch: 1| iterations complete: 1055 | loss at this iteration 3.9478877756594484\n",
            "Epoch: 1| iterations complete: 1080 | loss at this iteration 3.751200615738829\n",
            "Epoch: 1| iterations complete: 1105 | loss at this iteration 3.922820938971099\n",
            "Epoch: 1| iterations complete: 1130 | loss at this iteration 3.8278339690763383\n",
            "Epoch: 1| iterations complete: 1155 | loss at this iteration 3.796893154735417\n",
            "Epoch: 1| iterations complete: 1180 | loss at this iteration 3.9253384079784155\n",
            "Epoch: 1| iterations complete: 1205 | loss at this iteration 3.6792242740823116\n",
            "Epoch: 1| iterations complete: 1230 | loss at this iteration 3.970331674446162\n",
            "Epoch: 1| iterations complete: 1255 | loss at this iteration 3.9443141563468553\n",
            "Epoch: 1| iterations complete: 1280 | loss at this iteration 3.7367509138753556\n",
            "Epoch: 1| iterations complete: 1305 | loss at this iteration 3.77780548346777\n",
            "Epoch: 1| iterations complete: 1330 | loss at this iteration 3.857144206042219\n",
            "Epoch: 1| iterations complete: 1355 | loss at this iteration 3.840725119516424\n",
            "Epoch: 1| iterations complete: 1380 | loss at this iteration 3.85592698627054\n",
            "Epoch: 1| iterations complete: 1405 | loss at this iteration 3.788517311466047\n",
            "Epoch: 1| iterations complete: 1430 | loss at this iteration 3.698536806529412\n",
            "Epoch: 1| iterations complete: 1455 | loss at this iteration 3.9303926161143843\n",
            "Epoch: 1| iterations complete: 1480 | loss at this iteration 3.6668277272748155\n",
            "Epoch: 1| iterations complete: 1505 | loss at this iteration 3.6836151620395357\n",
            "Epoch: 1| iterations complete: 1530 | loss at this iteration 3.7850436872891606\n",
            "Epoch: 1| iterations complete: 1555 | loss at this iteration 3.8706136509703546\n",
            "Epoch: 1| iterations complete: 1580 | loss at this iteration 3.5438214397066847\n",
            "Epoch: 1| iterations complete: 1605 | loss at this iteration 3.792283464802686\n",
            "Epoch: 1| iterations complete: 1630 | loss at this iteration 3.749174864514368\n",
            "Epoch: 1| iterations complete: 1655 | loss at this iteration 3.741917801839419\n",
            "Epoch: 1| iterations complete: 1680 | loss at this iteration 3.7440986467690407\n",
            "Epoch: 1| iterations complete: 1705 | loss at this iteration 3.769576284699142\n",
            "Epoch: 1| iterations complete: 1730 | loss at this iteration 3.6477228346953376\n",
            "Epoch: 1| iterations complete: 1755 | loss at this iteration 3.992798518866766\n",
            "Epoch: 1| iterations complete: 1780 | loss at this iteration 3.793541804180918\n",
            "Epoch: 1| iterations complete: 1805 | loss at this iteration 3.4382904626380064\n",
            "Epoch: 1| iterations complete: 1830 | loss at this iteration 3.6705386804752664\n",
            "Epoch: 1| iterations complete: 1855 | loss at this iteration 3.718915082174789\n",
            "Epoch: 1| iterations complete: 1880 | loss at this iteration 3.9546389632752903\n",
            "Epoch: 1| iterations complete: 1905 | loss at this iteration 3.689173757878384\n",
            "Epoch: 1| iterations complete: 1930 | loss at this iteration 3.8333871905501704\n",
            "Epoch: 1| iterations complete: 1955 | loss at this iteration 3.7903985957036146\n",
            "Epoch: 1| iterations complete: 1980 | loss at this iteration 3.5956887510870907\n",
            "Epoch: 1| iterations complete: 2005 | loss at this iteration 3.7985169999488164\n",
            "Epoch: 1| iterations complete: 2030 | loss at this iteration 3.9902907798604637\n",
            "Epoch: 1| iterations complete: 2055 | loss at this iteration 3.7005441353615858\n",
            "Epoch: 1| iterations complete: 2080 | loss at this iteration 3.434979870200049\n",
            "Epoch: 1| iterations complete: 2105 | loss at this iteration 3.6042355423991754\n",
            "Epoch: 1| iterations complete: 2130 | loss at this iteration 3.6341815717298607\n",
            "Epoch: 1| iterations complete: 2155 | loss at this iteration 3.7013899899704756\n",
            "Epoch: 1| iterations complete: 2180 | loss at this iteration 3.675351923628363\n",
            "Epoch: 1| iterations complete: 2205 | loss at this iteration 3.6499679859845573\n",
            "Epoch: 1| iterations complete: 2230 | loss at this iteration 3.6304416113666127\n",
            "Epoch: 1| iterations complete: 2255 | loss at this iteration 3.8326007532727435\n",
            "Epoch: 1| iterations complete: 2280 | loss at this iteration 3.7110098232270072\n",
            "Epoch: 1| iterations complete: 2305 | loss at this iteration 3.456941970635176\n",
            "Epoch: 1| iterations complete: 2330 | loss at this iteration 3.579942432888037\n",
            "Epoch: 1| iterations complete: 2355 | loss at this iteration 3.7199196284700644\n",
            "Epoch: 1| iterations complete: 2380 | loss at this iteration 3.8262867979885873\n",
            "Epoch: 1| iterations complete: 2405 | loss at this iteration 3.72900825340116\n",
            "Epoch: 1| iterations complete: 2430 | loss at this iteration 3.3394711793677496\n",
            "Epoch: 1| iterations complete: 2455 | loss at this iteration 3.817463971543072\n",
            "Epoch: 1| iterations complete: 2480 | loss at this iteration 3.897587173983417\n",
            "Epoch: 1| iterations complete: 2505 | loss at this iteration 3.6348692420786053\n",
            "Epoch: 1| iterations complete: 2530 | loss at this iteration 3.5973734246645734\n",
            "Epoch: 1| iterations complete: 2555 | loss at this iteration 3.5975370079660514\n",
            "Epoch: 1| iterations complete: 2580 | loss at this iteration 3.6912013622606734\n",
            "Epoch: 1| iterations complete: 2605 | loss at this iteration 3.8481724385480236\n",
            "Epoch: 1| iterations complete: 2630 | loss at this iteration 3.7003569804156493\n",
            "Epoch: 1| iterations complete: 2655 | loss at this iteration 3.913990386959261\n",
            "Epoch: 1| iterations complete: 2680 | loss at this iteration 3.828322883388505\n",
            "Epoch: 1| iterations complete: 2705 | loss at this iteration 3.7051625756381696\n",
            "Epoch: 1| iterations complete: 2730 | loss at this iteration 3.650930102043484\n",
            "Epoch: 1| iterations complete: 2755 | loss at this iteration 3.4514354868742325\n",
            "Epoch: 1| iterations complete: 2780 | loss at this iteration 3.578020214741587\n",
            "Epoch: 1| iterations complete: 2805 | loss at this iteration 3.80201594479401\n",
            "Epoch: 1| iterations complete: 2830 | loss at this iteration 3.473618845678478\n",
            "Epoch: 1| iterations complete: 2855 | loss at this iteration 3.9691029803038678\n",
            "Epoch: 1| iterations complete: 2880 | loss at this iteration 3.7980600171237193\n",
            "Epoch: 1| iterations complete: 2905 | loss at this iteration 3.619949074646899\n",
            "Epoch: 1| iterations complete: 2930 | loss at this iteration 3.6629295016769174\n",
            "Epoch: 1| iterations complete: 2955 | loss at this iteration 3.334291618471756\n",
            "Epoch: 1| iterations complete: 2980 | loss at this iteration 3.823812361734195\n",
            "Epoch: 1| iterations complete: 3005 | loss at this iteration 3.676584805958069\n",
            "Epoch: 1| iterations complete: 3030 | loss at this iteration 3.5420114423412783\n",
            "Epoch: 1| iterations complete: 3055 | loss at this iteration 3.6002932308048083\n",
            "Epoch: 1| iterations complete: 3080 | loss at this iteration 3.746080643235773\n",
            "Epoch: 1| iterations complete: 3105 | loss at this iteration 3.4860911288704064\n",
            "Epoch: 1| iterations complete: 3130 | loss at this iteration 3.613854227892548\n",
            "Epoch: 1| iterations complete: 3155 | loss at this iteration 3.5212807933888843\n",
            "Epoch: 1| iterations complete: 3180 | loss at this iteration 3.8454431921545527\n",
            "Epoch: 1| iterations complete: 3205 | loss at this iteration 3.7282037137485133\n",
            "Epoch: 1| iterations complete: 3230 | loss at this iteration 3.6918539936695014\n",
            "Epoch: 1| iterations complete: 3255 | loss at this iteration 3.826613282672583\n",
            "Epoch: 1| iterations complete: 3280 | loss at this iteration 3.7279734403333245\n",
            "Epoch: 1| iterations complete: 3305 | loss at this iteration 3.8070232042452186\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-746ad8b640fc>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0minput_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_target_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Run a training iteration with batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                   decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip,teacher_forcing_ratio)\n",
            "\u001b[0;32m<ipython-input-101-b7a68da2c8c7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size, clip, teacher_forcing_ratio, max_length)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mTF_flag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_target_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             decoder_output, decoder_hidden = decoder(\n\u001b[0m\u001b[1;32m     43\u001b[0m                 \u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-100-36aeaeeb25b0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_step, last_hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# Forward through unidirectional GRU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mrnn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;31m# Calculate attention weights from the current GRU output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    994\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    237\u001b[0m                           msg: str = 'Expected hidden size {}, got {}') -> None:\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_weights_have_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden size (2, 64, 500), got [2, 9, 500]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "# Save the entire model\n",
        "torch.save(encoder.state_dict, 'encoder_lu_gru_model.pth')\n",
        "torch.save(decoder.state_dict, 'decoder_lu_gru_model.pth')\n",
        "enc_path = os.path.join(\"/content/gdrive/My Drive/data/model\", 'encoder_lu_gru_model.pth')\n",
        "dec_path = os.path.join(\"/content/gdrive/My Drive/data/model\", 'decoder_lu_gru_model.pth')\n",
        "enc_path_state= os.path.join(\"/content/gdrive/My Drive/data/model_dict\", 'encoder_lu_gru_model.pth')\n",
        "dec_path_state= os.path.join(\"/content/gdrive/My Drive/data/model_dict\", 'decoder_lu_gru_model.pth')\n",
        "# Save only the model state dictionary\n",
        "torch.save(encoder.state_dict(), enc_path_state)\n",
        "torch.save(encoder,enc_path )\n",
        "torch.save(decoder.state_dict(), dec_path_state)\n",
        "torch.save(decoder,dec_path )\n"
      ],
      "metadata": {
        "id": "LAFaV982u-M7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}